{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(x_train): 60000\n",
      "[28, 10]\n",
      "[28]\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.01748016 0.02673778 0.         0.         0.00602611 0.\n",
      "  0.         0.         0.         0.         0.03430181 0.023855\n",
      "  0.00654872 0.         0.         0.         0.03825076 0.\n",
      "  0.07328451 0.         0.02354929 0.03025666 0.         0.04835717\n",
      "  0.         0.02556546 0.03385373 0.04659563]\n",
      " [0.         0.         0.         0.         0.06535421 0.\n",
      "  0.         0.         0.05645705 0.         0.13004425 0.01549844\n",
      "  0.         0.04896671 0.         0.         0.1036097  0.07355008\n",
      "  0.03742907 0.         0.         0.         0.         0.\n",
      "  0.         0.12024324 0.14770994 0.        ]\n",
      " [0.         0.         0.         0.         0.0027197  0.\n",
      "  0.04302675 0.         0.11189289 0.         0.09072255 0.\n",
      "  0.         0.04395699 0.00933373 0.04975676 0.08487647 0.01378354\n",
      "  0.00572389 0.         0.02748866 0.         0.         0.\n",
      "  0.         0.12651348 0.16967528 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.021663   0.         0.0808398  0.         0.07567543 0.\n",
      "  0.         0.03423792 0.00101215 0.0327794  0.08129841 0.00456038\n",
      "  0.02017812 0.         0.03672768 0.         0.         0.\n",
      "  0.         0.11122777 0.15737762 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.00828841 0.         0.0364771  0.         0.02291169 0.\n",
      "  0.         0.01047879 0.00830038 0.008518   0.04492189 0.\n",
      "  0.01576747 0.         0.02269142 0.         0.         0.\n",
      "  0.         0.06107318 0.10030939 0.0093521 ]\n",
      " [0.03836422 0.         0.01341372 0.         0.         0.01680471\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.0099496  0.\n",
      "  0.02884961 0.         0.0285176  0.00626036 0.         0.02896094\n",
      "  0.         0.05333598 0.08157708 0.04866493]\n",
      " [0.05666146 0.         0.01858671 0.         0.         0.01886109\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05889048 0.         0.04217981 0.01229247 0.         0.05158316\n",
      "  0.         0.0669031  0.10159926 0.07421101]\n",
      " [0.04424474 0.         0.00426109 0.         0.         0.00784304\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06376532 0.         0.03909021 0.00079017 0.         0.04093649\n",
      "  0.         0.05953597 0.09062535 0.06668206]\n",
      " [0.00458736 0.         0.         0.         0.         0.\n",
      "  0.03779557 0.         0.03694625 0.         0.         0.\n",
      "  0.01871822 0.         0.         0.01730741 0.         0.\n",
      "  0.08863883 0.         0.         0.         0.         0.\n",
      "  0.         0.01105253 0.05268183 0.01396778]\n",
      " [0.01045329 0.00026588 0.         0.         0.00459926 0.\n",
      "  0.01541175 0.         0.02767995 0.         0.02607668 0.01160748\n",
      "  0.02473249 0.         0.         0.         0.         0.01378152\n",
      "  0.0738868  0.         0.         0.         0.         0.00621534\n",
      "  0.         0.01667231 0.         0.        ]\n",
      " [0.02621182 0.0039462  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.00181005 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10302293 0.         0.         0.         0.         0.03307459\n",
      "  0.         0.04530415 0.04354399 0.04714802]\n",
      " [0.02551171 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.01098537 0.\n",
      "  0.         0.         0.         0.         0.0165434  0.\n",
      "  0.09723056 0.         0.         0.         0.         0.01548411\n",
      "  0.         0.07768489 0.0828326  0.04813599]\n",
      " [0.01116125 0.         0.         0.         0.02727178 0.\n",
      "  0.         0.         0.         0.         0.04559217 0.\n",
      "  0.         0.00793533 0.         0.         0.03210801 0.03480392\n",
      "  0.07089017 0.         0.         0.         0.         0.\n",
      "  0.         0.10177225 0.07893473 0.0061889 ]\n",
      " [0.02698384 0.         0.         0.         0.         0.\n",
      "  0.00097598 0.         0.02877774 0.         0.02568768 0.\n",
      "  0.         0.         0.         0.         0.00186984 0.\n",
      "  0.12629043 0.         0.         0.         0.         0.\n",
      "  0.         0.09394979 0.08351476 0.02893183]\n",
      " [0.01762724 0.         0.         0.         0.         0.\n",
      "  0.03111188 0.         0.05560888 0.         0.01469027 0.\n",
      "  0.         0.         0.         0.03756982 0.         0.\n",
      "  0.14676633 0.         0.0004858  0.         0.         0.\n",
      "  0.         0.11704206 0.12784247 0.03102896]\n",
      " [0.01644074 0.         0.         0.         0.         0.\n",
      "  0.00085254 0.         0.01004637 0.         0.         0.\n",
      "  0.         0.         0.         0.0299817  0.         0.\n",
      "  0.09267729 0.         0.01315921 0.         0.         0.\n",
      "  0.         0.07092497 0.10192703 0.04632806]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.01564954 0.         0.04468219 0.         0.02532769 0.\n",
      "  0.         0.         0.         0.04668204 0.03436052 0.\n",
      "  0.06634824 0.         0.04312603 0.         0.         0.\n",
      "  0.         0.09648092 0.13965487 0.02023894]\n",
      " [0.         0.         0.         0.         0.0534489  0.\n",
      "  0.03701807 0.         0.11353236 0.         0.10966916 0.\n",
      "  0.         0.04975216 0.04810934 0.01796302 0.0962729  0.02871083\n",
      "  0.         0.         0.0064699  0.         0.         0.\n",
      "  0.         0.11479117 0.12461423 0.        ]\n",
      " [0.0585979  0.         0.         0.         0.07174546 0.\n",
      "  0.         0.         0.02940173 0.         0.11493647 0.\n",
      "  0.         0.01027856 0.01944368 0.         0.1047096  0.\n",
      "  0.01168374 0.         0.01006486 0.         0.         0.\n",
      "  0.         0.14723466 0.08145888 0.        ]\n",
      " [0.09485141 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.01003646 0.\n",
      "  0.         0.         0.         0.         0.06193022 0.\n",
      "  0.11450395 0.         0.05824487 0.         0.         0.08244261\n",
      "  0.         0.14939535 0.15929016 0.08277234]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Can not squeeze dim[2], expected a dimension of 1, got 28\n\t [[{{node metrics_16/acc/Squeeze}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1fb9cbeb0304>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Can not squeeze dim[2], expected a dimension of 1, got 28\n\t [[{{node metrics_16/acc/Squeeze}}]]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "mnist = tf.keras.datasets.mnist #28*28 images of hand-written digits 0-9\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "\n",
    "x_train=tf.keras.utils.normalize(x_train,axis=1)\n",
    "x_test=tf.keras.utils.normalize(x_test,axis=1)\n",
    "\n",
    "np.reshape(x_train,(len(x_train),1,784))\n",
    "\n",
    "print(\"len(x_train):\",len(x_train))\n",
    "\n",
    "model=tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "l=[784,400,200,100,50,25,10]\n",
    "l=[28,10]\n",
    "print(l)\n",
    "\n",
    "\n",
    "#Encoding the data from 128 parameters into 10 parameters\n",
    "for e in l:\n",
    "    model.add(tf.keras.layers.Dense(e,activation=tf.nn.relu))\n",
    "\n",
    "l.reverse()\n",
    "l=l[1:]\n",
    "print(l)\n",
    "#Decoding the data from 10 parameters into 128 parameters\n",
    "for e in l:\n",
    "    model.add(tf.keras.layers.Dense(e,activation=tf.nn.relu))\n",
    "\n",
    "#model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.predict(x_train[0]))\n",
    "\n",
    "model.fit(x_train,x_train,epochs=3)\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "[0.01748016 0.02673778 0.         0.         0.00602611 0.\n",
      " 0.         0.         0.         0.         0.03430181 0.023855\n",
      " 0.00654872 0.         0.         0.         0.03825076 0.\n",
      " 0.07328451 0.         0.02354929 0.03025666 0.         0.04835717\n",
      " 0.         0.02556546 0.03385373 0.04659563]\n",
      "[0.         0.         0.         0.         0.06535421 0.\n",
      " 0.         0.         0.05645705 0.         0.13004425 0.01549844\n",
      " 0.         0.04896671 0.         0.         0.1036097  0.07355008\n",
      " 0.03742907 0.         0.         0.         0.         0.\n",
      " 0.         0.12024324 0.14770994 0.        ]\n",
      "[0.         0.         0.         0.         0.0027197  0.\n",
      " 0.04302675 0.         0.11189289 0.         0.09072255 0.\n",
      " 0.         0.04395699 0.00933373 0.04975676 0.08487647 0.01378354\n",
      " 0.00572389 0.         0.02748866 0.         0.         0.\n",
      " 0.         0.12651348 0.16967528 0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.021663   0.         0.0808398  0.         0.07567543 0.\n",
      " 0.         0.03423792 0.00101215 0.0327794  0.08129841 0.00456038\n",
      " 0.02017812 0.         0.03672768 0.         0.         0.\n",
      " 0.         0.11122777 0.15737762 0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.00828841 0.         0.0364771  0.         0.02291169 0.\n",
      " 0.         0.01047879 0.00830038 0.008518   0.04492189 0.\n",
      " 0.01576747 0.         0.02269142 0.         0.         0.\n",
      " 0.         0.06107318 0.10030939 0.0093521 ]\n",
      "[0.03836422 0.         0.01341372 0.         0.         0.01680471\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.0099496  0.\n",
      " 0.02884961 0.         0.0285176  0.00626036 0.         0.02896094\n",
      " 0.         0.05333598 0.08157708 0.04866493]\n",
      "[0.05666146 0.         0.01858671 0.         0.         0.01886109\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.05889048 0.         0.04217981 0.01229247 0.         0.05158316\n",
      " 0.         0.0669031  0.10159926 0.07421101]\n",
      "[0.04424474 0.         0.00426109 0.         0.         0.00784304\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.06376532 0.         0.03909021 0.00079017 0.         0.04093649\n",
      " 0.         0.05953597 0.09062535 0.06668206]\n",
      "[0.00458736 0.         0.         0.         0.         0.\n",
      " 0.03779557 0.         0.03694625 0.         0.         0.\n",
      " 0.01871822 0.         0.         0.01730741 0.         0.\n",
      " 0.08863883 0.         0.         0.         0.         0.\n",
      " 0.         0.01105253 0.05268183 0.01396778]\n",
      "[0.01045329 0.00026588 0.         0.         0.00459926 0.\n",
      " 0.01541175 0.         0.02767995 0.         0.02607668 0.01160748\n",
      " 0.02473249 0.         0.         0.         0.         0.01378152\n",
      " 0.0738868  0.         0.         0.         0.         0.00621534\n",
      " 0.         0.01667231 0.         0.        ]\n",
      "[0.02621182 0.0039462  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00181005 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.10302293 0.         0.         0.         0.         0.03307459\n",
      " 0.         0.04530415 0.04354399 0.04714802]\n",
      "[0.02551171 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01098537 0.\n",
      " 0.         0.         0.         0.         0.0165434  0.\n",
      " 0.09723056 0.         0.         0.         0.         0.01548411\n",
      " 0.         0.07768489 0.0828326  0.04813599]\n",
      "[0.01116125 0.         0.         0.         0.02727178 0.\n",
      " 0.         0.         0.         0.         0.04559217 0.\n",
      " 0.         0.00793533 0.         0.         0.03210801 0.03480392\n",
      " 0.07089017 0.         0.         0.         0.         0.\n",
      " 0.         0.10177225 0.07893473 0.0061889 ]\n",
      "[0.02698384 0.         0.         0.         0.         0.\n",
      " 0.00097598 0.         0.02877774 0.         0.02568768 0.\n",
      " 0.         0.         0.         0.         0.00186984 0.\n",
      " 0.12629043 0.         0.         0.         0.         0.\n",
      " 0.         0.09394979 0.08351476 0.02893183]\n",
      "[0.01762724 0.         0.         0.         0.         0.\n",
      " 0.03111188 0.         0.05560888 0.         0.01469027 0.\n",
      " 0.         0.         0.         0.03756982 0.         0.\n",
      " 0.14676633 0.         0.0004858  0.         0.         0.\n",
      " 0.         0.11704206 0.12784247 0.03102896]\n",
      "[0.01644074 0.         0.         0.         0.         0.\n",
      " 0.00085254 0.         0.01004637 0.         0.         0.\n",
      " 0.         0.         0.         0.0299817  0.         0.\n",
      " 0.09267729 0.         0.01315921 0.         0.         0.\n",
      " 0.         0.07092497 0.10192703 0.04632806]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.01564954 0.         0.04468219 0.         0.02532769 0.\n",
      " 0.         0.         0.         0.04668204 0.03436052 0.\n",
      " 0.06634824 0.         0.04312603 0.         0.         0.\n",
      " 0.         0.09648092 0.13965487 0.02023894]\n",
      "[0.         0.         0.         0.         0.0534489  0.\n",
      " 0.03701807 0.         0.11353236 0.         0.10966916 0.\n",
      " 0.         0.04975216 0.04810934 0.01796302 0.0962729  0.02871083\n",
      " 0.         0.         0.0064699  0.         0.         0.\n",
      " 0.         0.11479117 0.12461423 0.        ]\n",
      "[0.0585979  0.         0.         0.         0.07174546 0.\n",
      " 0.         0.         0.02940173 0.         0.11493647 0.\n",
      " 0.         0.01027856 0.01944368 0.         0.1047096  0.\n",
      " 0.01168374 0.         0.01006486 0.         0.         0.\n",
      " 0.         0.14723466 0.08145888 0.        ]\n",
      "[0.09485141 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01003646 0.\n",
      " 0.         0.         0.         0.         0.06193022 0.\n",
      " 0.11450395 0.         0.05824487 0.         0.         0.08244261\n",
      " 0.         0.14939535 0.15929016 0.08277234]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for y in model.predict(x_train[0]):\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
